{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e126e6c",
   "metadata": {},
   "source": [
    "# Two sum\n",
    "\n",
    "Given an array of integers nums, and an integer target, return indices of the two numbers such that they add up to target. \n",
    "\n",
    "You may assume that each input would have exactly one solution, and you may not use the same element twice. \n",
    "\n",
    "You can return the answer in any order. \n",
    "\n",
    "Leetcode.com gives some examples so we'll use them as unit tests. Some contraints are given ss well but we'll see if we need them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3fdfe3",
   "metadata": {},
   "source": [
    "## Learning objective\n",
    "\n",
    "Use the boilerplate from Valid Anagram and start to expand boilerplate to what is important. \n",
    "\n",
    "Set up more, and useful unit tests before starting coding.\n",
    "\n",
    "### Setup a function ... \n",
    "\n",
    "Learnt the index function for lists!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5981d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoSum(nums: list[int], target: int) -> list[int]:\n",
    "    for idx, v in enumerate(nums):\n",
    "        vals = [n + v for n in nums[1+idx:]]\n",
    "        if target in vals:\n",
    "            return [idx, vals.index(target) + idx + 1]\n",
    "            \n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4a9a33",
   "metadata": {},
   "source": [
    "## Setup the unit tests.\n",
    "\n",
    "Notes: \n",
    "\n",
    "Worry about any order! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "229ab05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testExample1 (__main__.TestTwoSum) ... ok\n",
      "testExample2 (__main__.TestTwoSum) ... ok\n",
      "testExample3 (__main__.TestTwoSum) ... ok\n",
      "testExample4 (__main__.TestTwoSum) ... ok\n",
      "testExample5 (__main__.TestTwoSum) ... ok\n",
      "testExample6 (__main__.TestTwoSum) ... ok\n",
      "testExample7 (__main__.TestTwoSum) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.006s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x102ebd340>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestTwoSum(unittest.TestCase):\n",
    "\n",
    "    def testExample1(self):\n",
    "        nums = [2, 7, 11, 15]\n",
    "        target = 9\n",
    "        self.assertEqual(func(nums, target), [0, 1])\n",
    "\n",
    "    def testExample2(self):\n",
    "        nums = [3, 2, 4]\n",
    "        target = 6\n",
    "        self.assertEqual(func(nums, target), [1, 2])\n",
    "        \n",
    "    def testExample3(self):\n",
    "        nums = [3, 3]\n",
    "        target = 6\n",
    "        self.assertEqual(func(nums, target), [0, 1])\n",
    "        \n",
    "    def testExample4(self):\n",
    "        nums = [3, 3, 3]\n",
    "        target = 6\n",
    "        self.assertEqual(func(nums, target), [0, 1])\n",
    "        \n",
    "    def testExample5(self):\n",
    "        nums = [2, 3, 3, 3]\n",
    "        target = 6\n",
    "        self.assertEqual(func(nums, target), [1, 2])\n",
    "        \n",
    "    def testExample6(self):\n",
    "        nums = [2, 2, 3, 1]\n",
    "        target = 4\n",
    "        self.assertEqual(func(nums, target), [0, 1])\n",
    "        \n",
    "    def testExample7(self):\n",
    "        nums = [9, 9, 9, 9]\n",
    "        target = 4\n",
    "        self.assertEqual(func(nums, target), [])\n",
    "\n",
    "func = twoSum\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d38ba5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475 ns ± 3.38 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "\n",
    "ret = twoSum([2, 7, 11, 15], 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc67dfa6",
   "metadata": {},
   "source": [
    "Now let's compare this to the neetcode.io solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a40a99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tS_neet(nums: list[int], target: int) -> list[int]:\n",
    "    prevMap = {}\n",
    "    \n",
    "    for i, n in enumerate(nums):\n",
    "        diff = target - n\n",
    "        if diff in prevMap:\n",
    "            return [prevMap[diff], i]\n",
    "        prevMap[n] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cfd557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testExample1 (__main__.TestTwoSum) ... ok\n",
      "testExample2 (__main__.TestTwoSum) ... ok\n",
      "testExample3 (__main__.TestTwoSum) ... ok\n",
      "testExample4 (__main__.TestTwoSum) ... ok\n",
      "testExample5 (__main__.TestTwoSum) ... ok\n",
      "testExample6 (__main__.TestTwoSum) ... ok\n",
      "testExample7 (__main__.TestTwoSum) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: testExample7 (__main__.TestTwoSum)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/40/rzn221yn44nfyyt3kcv2xrcr0000gq/T/ipykernel_98012/2571907295.py\", line 38, in testExample7\n",
      "    self.assertEqual(func(nums, target), [])\n",
      "AssertionError: None != []\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.006s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1031c0250>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func = tS_neet\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "207fc175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276 ns ± 0.698 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "\n",
    "ret = tS_neet([2, 7, 11, 15], 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f1d414",
   "metadata": {},
   "source": [
    "So here I think my code is fine, except I still not get the unit tests right.  I over thought it and added a null test but the docs explictly say you may assume that the inputs have exactly one solution.  So this was not a useful test.\n",
    "\n",
    "My code is a lot slower.  The neetcode.io solution uses a dict to store the index of the first hit and then returns the two indices on the second hit.  I guess my list comprehension to get vals is the solw bit here. The neet code solution avoids this altogether. \n",
    "\n",
    "## Learning outcomes ... \n",
    "\n",
    "Read the question! \n",
    "\n",
    "Again, maybe I should really be worrying about speed here.  Is optimisation everything here? \n",
    "\n",
    "I can now run the unittests on the neetcode by using a globally defined func, but should I?   Probably not, but maybe I revel in being a dirty physicist rather than a software engineer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb51246a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
